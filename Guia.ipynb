{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Understanding Data:\n",
    "1) Hypothesis Generation\n",
    "2) Getting the system ready and loading the data\n",
    "3) Dataset Structure and Content\n",
    "4) Feature Extraction\n",
    "5) Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-c93342a6530a>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-c93342a6530a>\"\u001b[1;36m, line \u001b[1;32m8\u001b[0m\n\u001b[1;33m    or\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "### loc and iloc are row-first, column-second. .[:10] loc inlcuye el 1o y iloc es hasta 9\n",
    "\n",
    "# loc obtiene filas (o columnas) con particular labels del índice.\n",
    "# iloc obtiene filas (o columnas) en determinadas posiciones en el índice (por lo que solo toma números enteros).\n",
    "# \n",
    "cols = ['country', 'variety']\n",
    "df = reviews.loc[:99, cols]\n",
    "or\n",
    "\n",
    "cols_idx = [0, 11]\n",
    "df = reviews.iloc[:100, cols_idx]\n",
    "\n",
    "#valores unicos\n",
    "reviews.taster_name.unique()\n",
    "\n",
    "\n",
    "#descripcion\n",
    "reviews.points.describe()\n",
    "\n",
    "#contador de valores\n",
    "\n",
    "reviews.taster_name.value_counts()\n",
    "\n",
    "#subdataset\n",
    "data = full_data.loc[:, [\"CLASS\", \"COUNTY\", \"geometry\"]].copy()\n",
    "\n",
    "\n",
    "# maps \n",
    "\n",
    "review_points_mean = reviews.points.mean()\n",
    "reviews.points.map(lambda p: p - review_points_mean)\n",
    "\n",
    "#contar variables\n",
    "reviews_per_country = reviews.country.value_counts()\n",
    "\n",
    "\n",
    "def remean_points(row):\n",
    "    row.points = row.points - review_points_mean\n",
    "    return row\n",
    "\n",
    "reviews.apply(remean_points, axis='columns')\n",
    "\n",
    "\n",
    "\n",
    "#I'm an economical wine buyer. Which wine is the \"best bargain\"? Create a variable bargain_wine with the title of the wine with the highest points-to-price ratio in the dataset\n",
    "bargain_idx = (reviews.points / reviews.price).idxmax()\n",
    "bargain_wine = reviews.loc[bargain_idx, 'title']\n",
    "\n",
    "\n",
    "#CONTADOR DE PALBRAS EN DSECRPCION\n",
    "\n",
    "n_trop = reviews.description.map(lambda desc: \"tropical\" in desc).sum()\n",
    "n_fruity = reviews.description.map(lambda desc: \"fruity\" in desc).sum()\n",
    "descriptor_counts = pd.Series([n_trop, n_fruity], index=['tropical', 'fruity'])\n",
    "\n",
    "# aplicar rattings de vino seguno su puntuacion(canada tiene 5 por pagar)\n",
    "\n",
    "def stars(row):\n",
    "    if row.country == 'Canada':\n",
    "        return 3\n",
    "    elif row.points >= 95:\n",
    "        return 3\n",
    "    elif row.points >= 85:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "star_ratings = reviews.apply(stars, axis='columns')\n",
    "\n",
    "\n",
    "# obtener mas barato para cada categoria \n",
    "reviews.groupby('points').price.min()\n",
    "\n",
    "#mejor obejto segun dos categorias\n",
    "\n",
    "reviews.groupby(['country', 'province']).apply(lambda df: df.loc[df.points.idxmax()])\n",
    "\n",
    "\n",
    "#analisis estadistico simple de nuestro dataset\n",
    "reviews.groupby(['country']).price.agg([len, min, max])\n",
    "\n",
    "#Ordenamiento de datos\n",
    "countries_reviewed.sort_values(by='len', ascending=False)\n",
    "\n",
    "# Ordenar con dos variables\n",
    "\n",
    "countries_reviewed.sort_values(by=['country', 'len'])\n",
    "\n",
    "# que vino es mejor por una cierta cantidad de dinero\n",
    "best_rating_per_price = reviews.groupby('price')['points'].max().sort_index()\n",
    "# minimo y maximo por variedad\n",
    "price_extremes = reviews.groupby(\"variety\").price.agg([min,max])\n",
    "\n",
    "\n",
    "# Remplazar NaN  por un valor determinado\n",
    "reviews.region_2.fillna(\"Unknown\")\n",
    "\n",
    "# Remplazar un valor por otro\n",
    "reviews.taster_twitter_handle.replace(\"@kerinokeefe\", \"@kerino\")\n",
    "\n",
    "# Re indexar fila\n",
    "\n",
    "reindexed = reviews.rename_axis('wines', axis='rows')\n",
    "\n",
    "loc = por nombre\n",
    "iloc =  por indice\n",
    "\n",
    "\n",
    "\n",
    "# Sacar valor si:\n",
    "print('Old size: %d' % len(train_df))\n",
    "train_df = train_df[(train_df.abs_diff_longitude < 5.0) & (train_df.abs_diff_latitude < 5.0)]\n",
    "print('New size: %d' % len(train_df))\n",
    "\n",
    "# Conditional selection\n",
    "data.loc[data.country == 'Italy']\n",
    "# dos condiciones\n",
    "reviews.loc[(reviews.country == 'Italy') & (reviews.points >= 90)]\n",
    "# or\n",
    "reviews.loc[(reviews.country == 'Italy') | (reviews.points >= 90)]\n",
    "#is in\n",
    "reviews.loc[reviews.country.isin(['Italy', 'France'])]\n",
    "\n",
    "#asignar data\n",
    "reviews['index_backwards'] = range(len(reviews), 0, -1)\n",
    "reviews['index_backwards']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets desbalanceados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambiar tipo de mustreo\n",
    "* submusetreo \n",
    "* sobre muestreo aleatorio( datasets no tan grandes)\n",
    "* SMOTE:\n",
    "\n",
    "\n",
    "#### en estos modelos no hay que usar la precission para medirlos, hay que utilizar\n",
    "* presisicion y especifidad\n",
    "* sensebilidad o recall\n",
    "* puntaje f1 \n",
    "* auc\n",
    "\n",
    "https://imbalanced-learn.readthedocs.io/en/stable/over_sampling.html\n",
    "\n",
    "### aca son mas utiles los modelos\n",
    "\n",
    "Check by using Different Metrices\n",
    "Accuracy metric is not best metric to use when evaluating imbalanced class as it can be mislead for the classification.\n",
    "Following are some metrics give us the good insights on the imbalanced dataset\n",
    "\n",
    "* 1. Confusion Metrics : confusion metrics show the clearly classification of the predicted class vs actual class.We can also see how many data point wrongly classified. \n",
    "* 2. Precision : We can get the precision by number of all positive classified value divided by all positive predicted value.It's measure the classifier's exactness.Low presicion indicates the high number of false positive. \n",
    "* 3. Recall : Recall is a metric that quantifies the number of correct positive predictions made out of all positive predictions that could have been made. Unlike precision that only comments on the correct positive predictions out of all positive predictions, recall provides an indication of missed positive predictions. \n",
    "* 4. F1-score : The F1-measure, which weights precision and recall equally, is the variant most often used when learning from imbalanced data. \n",
    "* 5. Classification Report : All above metioned things are auto-generated in the classication report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balancear modelos\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sobre muestreo aleatorio( datasets no tan grandes)\n",
    "from sklearn.utils import resample\n",
    " #Seprate the input feature and target \n",
    "X = data.drop('Class',axis=1)\n",
    "y= data['Claspipppis']\n",
    "\n",
    "#As told split the data into train and test dataset\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42,test_size=0.25)\n",
    "\n",
    "X = pd.concat([X_train, y_train], axis=1)\n",
    "X.head()\n",
    "\n",
    "\n",
    "#Seperate minority and majority class:\n",
    "not_fraud = X[X['Class'] == 0]\n",
    "fraud = X[X['Class'] == 1]\n",
    "print(f'Total sample which are not fraud : {len(not_fraud)}')\n",
    "print(f'Total Fraud samples : {len(fraud)}')\n",
    "\n",
    "#Now use the oversampling techniques\n",
    "random_sampling = resample(fraud,\n",
    "                          replace=True,\n",
    "                           n_samples = len(not_fraud),\n",
    "                           random_state = 42\n",
    "                          )\n",
    "\n",
    "#combine minority and upsample data\n",
    "upsample = pd.concat([not_fraud,random_sampling])\n",
    "\n",
    "#Check new values are balances for the both classes or not\n",
    "upsample['Class'].value_counts()\n",
    "\n",
    "X_train = upsample.drop('Class',axis=1)\n",
    "y_train = upsample['Class']\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submuestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smote\n",
    "#import the libaray for SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Separate input features and target\n",
    "y = data[\"Class\"]\n",
    "X = data.drop('Class', axis=1)\n",
    "\n",
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "sm = SMOTE(random_state=27,sampling_strategy=1.0)\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "smote_logistic = LogisticRegression()\n",
    "smote_logistic.fit(X_train,y_train)\n",
    "\n",
    "smote_pred = smote_logistic.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar valores unicos de una variable\n",
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medir datasets desbalanciados\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(random_forest_pred,y_test)\n",
    "\n",
    "\n",
    "pd.DataFrame(confusion_matrix(random_forest_pred,y_test))\n",
    "\n",
    "\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test,random_forest_pred),cmap='viridis',annot=True,fmt='.2f')\n",
    "plt.savefig('random.png')\n",
    "plt.show()\n",
    "\n",
    "recall_score(random_forest_pred,y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(random_forest_pred,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convertir variables de formato tiempo en otras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new columns for timestamp features day, hour, minute, and second\n",
    "clicks = click_data.copy()\n",
    "clicks['day'] = clicks['click_time'].dt.day.astype('uint8')\n",
    "# Fill in the rest\n",
    "clicks['hour'] =  clicks['click_time'].dt.hour.astype(\"uint8\")\n",
    "clicks['minute'] = clicks[\"click_time\"].dt.minute.astype(\"uint8\")\n",
    "clicks['second'] = clicks[\"click_time\"].dt.second.astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = ks.assign(hour=ks.launched.dt.hour,\n",
    "               day=ks.launched.dt.day,\n",
    "               month=ks.launched.dt.month,\n",
    "               year=ks.launched.dt.year)\n",
    "# Since ks and encoded have the same index and I can easily join them\n",
    "data = ks[['goal', 'hour', 'day', 'month', 'year', 'outcome']].join(encoded)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis GeoEspacial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you learned in the first tutorial, for an arbitrary GeoDataFrame, the type in the \"geometry\" column depends on what we are trying to show: for instance, we might use:\n",
    "\n",
    "  * a Point for the epicenter of an earthquake,\n",
    "  * a LineString for a street, or\n",
    "  * a Polygon to show country boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "wild_lands.plot()\n",
    "\n",
    "\n",
    "# View the first five entries in the \"geometry\" column\n",
    "wild_lands.geometry.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar dataset con cada tipo dde dato\n",
    "\n",
    "# Campsites in New York state (Point)\n",
    "POI_data = gpd.read_file(\"../input/geospatial-learn-course-data/DEC_pointsinterest/DEC_pointsinterest/Decptsofinterest.shp\")\n",
    "campsites = POI_data.loc[POI_data.ASSET=='PRIMITIVE CAMPSITE'].copy()\n",
    "\n",
    "# Foot trails in New York state (LineString)\n",
    "roads_trails = gpd.read_file(\"../input/geospatial-learn-course-data/DEC_roadstrails/DEC_roadstrails/Decroadstrails.shp\")\n",
    "trails = roads_trails.loc[roads_trails.ASSET=='FOOT TRAIL'].copy()\n",
    "\n",
    "# County boundaries in New York state (Polygon)\n",
    "counties = gpd.read_file(\"../input/geospatial-learn-course-data/NY_county_boundaries/NY_county_boundaries/NY_county_boundaries.shp\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#grafico\n",
    "\n",
    "# Define a base map with county boundaries\n",
    "ax = counties.plot(figsize=(10,10), color='none', edgecolor='gainsboro', zorder=3)\n",
    "\n",
    "# Add wild lands, campsites, and foot trails to the base map\n",
    "wild_lands.plot(color='lightgreen', ax=ax)\n",
    "campsites.plot(color='maroon', markersize=2, ax=ax)\n",
    "trails.plot(color='black', markersize=1, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### crs(analisis de coordenadas)\n",
    "\n",
    "# Load a GeoDataFrame containing regions in Ghana\n",
    "#epsg:32630( mercator projetion), hay que usar . EPSG 4326 (sistema de coordenadas)\n",
    "regions = gpd.read_file(\"../input/geospatial-learn-course-data/ghana/ghana/Regions/Map_of_Regions_in_Ghana.shp\")\n",
    "print(regions.crs)\n",
    "# Convert the DataFrame to a GeoDataFrame\n",
    "facilities = gpd.GeoDataFrame(facilities_df, geometry=gpd.points_from_xy(facilities_df.Longitude, facilities_df.Latitude))\n",
    "facilities.crs = {'init': 'epsg:4326'}\n",
    "\n",
    "# Create a map\n",
    "ax = regions.plot(figsize=(8,8), color='whitesmoke', linestyle=':', edgecolor='black')\n",
    "facilities.to_crs(epsg=32630).plot(markersize=1, ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the area (in square meters) of each polygon in the GeoDataFrame \n",
    "regions.loc[:, \"AREA\"] = regions.geometry.area / 10**6\n",
    "\n",
    "print(\"Area of Ghana: {} square kilometers\".format(regions.AREA.sum()))\n",
    "print(\"CRS:\", regions.crs)\n",
    "regions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRAFICOS INTERACTIVOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium import Choropleth, Circle, Marker\n",
    "from folium.plugins import HeatMap, MarkerCluster\n",
    "\n",
    "# Create a map\n",
    "m_1 = folium.Map(location=[42.32,-71.0589], tiles='openstreetmap', zoom_start=10)\n",
    "\n",
    "# Display the map\n",
    "m_1\n",
    "daytime_robberies = crimes[((crimes.OFFENSE_CODE_GROUP == 'Robbery') & \\\n",
    "                            (crimes.HOUR.isin(range(9,18))))]\n",
    "\n",
    "# Create a map\n",
    "m_2 = folium.Map(location=[42.32,-71.0589], tiles='cartodbpositron', zoom_start=13)\n",
    "\n",
    "# Add points to the map\n",
    "for idx, row in daytime_robberies.iterrows():\n",
    "    Marker([row['Lat'], row['Long']]).add_to(m_2)\n",
    "\n",
    "# Display the map\n",
    "m_2\n",
    " \n",
    "\n",
    "\n",
    "## Bubble maps\n",
    "# Create a base map\n",
    "m_4 = folium.Map(location=[42.32,-71.0589], tiles='cartodbpositron', zoom_start=13)\n",
    "\n",
    "def color_producer(val):\n",
    "    if val <= 12:\n",
    "        return 'forestgreen'\n",
    "    else:\n",
    "        return 'darkred'\n",
    "\n",
    "# Add a bubble map to the base map\n",
    "for i in range(0,len(daytime_robberies)):\n",
    "    Circle(\n",
    "        location=[daytime_robberies.iloc[i]['Lat'], daytime_robberies.iloc[i]['Long']],\n",
    "        radius=20,\n",
    "        color=color_producer(daytime_robberies.iloc[i]['HOUR'])).add_to(m_4)\n",
    "\n",
    "# Display the map\n",
    "m_4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Heat map\n",
    "# Create a base map\n",
    "m_5 = folium.Map(location=[42.32,-71.0589], tiles='cartodbpositron', zoom_start=12)\n",
    "\n",
    "# Add a heatmap to the base map\n",
    "HeatMap(data=crimes[['Lat', 'Long']], radius=10).add_to(m_5)\n",
    "\n",
    "# Display the map\n",
    "m_5# Create a base map\n",
    "m_5 = folium.Map(location=[42.32,-71.0589], tiles='cartodbpositron', zoom_start=12)\n",
    "\n",
    "# Add a heatmap to the base map\n",
    "HeatMap(data=crimes[['Lat', 'Long']], radius=10).add_to(m_5)\n",
    "\n",
    "# Display the map\n",
    "m_5\n",
    "\n",
    "# Choropleth maps\n",
    "\n",
    "\n",
    "# GeoDataFrame with geographical boundaries of Boston police districts\n",
    "districts_full = gpd.read_file('../input/geospatial-learn-course-data/Police_Districts/Police_Districts/Police_Districts.shp')\n",
    "districts = districts_full[[\"DISTRICT\", \"geometry\"]].set_index(\"DISTRICT\")\n",
    "districts.head()\n",
    "\n",
    "\n",
    "# Number of crimes in each police district\n",
    "plot_dict = crimes.DISTRICT.value_counts()\n",
    "plot_dict.head()\n",
    "\n",
    "#It's very important that plot_dict has the same index as districts - this is how the code knows how to match the geographical boundaries with appropriate colors.\n",
    "\n",
    "# Create a base map\n",
    "m_6 = folium.Map(location=[42.32,-71.0589], tiles='cartodbpositron', zoom_start=12)\n",
    "\n",
    "# Add a choropleth map to the base map\n",
    "Choropleth(geo_data=districts.__geo_interface__, \n",
    "           data=plot_dict, \n",
    "           key_on=\"feature.id\", \n",
    "           fill_color='YlGnBu', \n",
    "           legend_name='Major criminal incidents (Jan-Aug 2018)'\n",
    "          ).add_to(m_6)\n",
    "\n",
    "# Display the map\n",
    "m_6\n",
    "\n",
    "\n",
    "\n",
    "# Recibe mapa y archivo httml , guarda el mapa en el httml configuraod para que sea visible en cualquier navegador\n",
    "def embed_map(m, file_name):\n",
    "    from IPython.display import IFrame\n",
    "    m.save(file_name)\n",
    "    return IFrame(file_name, width='100%', height='500px')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GeoCode\n",
    "\n",
    "from geopandas.tools import geocode\n",
    "result = geocode(\"The Great Pyramid of Giza\", provider=\"nominatim\")\n",
    "result\n",
    "point = result.geometry.iloc[0]\n",
    "print(\"Latitude:\", point.y)\n",
    "print(\"Longitude:\", point.x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "universities = pd.read_csv(\"../input/geospatial-learn-course-data/top_universities.csv\")\n",
    "universities.head()\n",
    "\n",
    "\n",
    "def my_geocoder(row):\n",
    "    try:\n",
    "        point = geocode(row, provider='nominatim').geometry.iloc[0]\n",
    "        return pd.Series({'Latitude': point.y, 'Longitude': point.x, 'geometry': point})\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "universities[['Latitude', 'Longitude', 'geometry']] = universities.apply(lambda x: my_geocoder(x['Name']), axis=1)\n",
    "\n",
    "print(\"{}% of addresses were geocoded!\".format(\n",
    "    (1 - sum(np.isnan(universities[\"Latitude\"])) / len(universities)) * 100))\n",
    "\n",
    "# Drop universities that were not successfully geocoded\n",
    "universities = universities.loc[~np.isnan(universities[\"Latitude\"])]\n",
    "universities = gpd.GeoDataFrame(universities, geometry=universities.geometry)\n",
    "universities.crs = {'init': 'epsg:4326'}\n",
    "universities.head()\n",
    "\n",
    "\n",
    "# Create a map\n",
    "m = folium.Map(location=[54, 15], tiles='openstreetmap', zoom_start=2)\n",
    "\n",
    "# Add points to the map\n",
    "for idx, row in universities.iterrows():\n",
    "    Marker([row['Latitude'], row['Longitude']], popup=row['Name']).add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m\n",
    "\n",
    "# unir capop con ca high earnens con ca median age\n",
    "\n",
    "cols_to_add = CA_pop.join([CA_high_earners, CA_median_age]).reset_index()\n",
    "\n",
    "CA_stats = CA_counties.merge(cols_to_add, on=\"GEOID\")\n",
    "    \n",
    "    \n",
    "#Spatial joins  \n",
    "# Use spatial join to match universities to countries in Europe\n",
    "european_universities = gpd.sjoin(universities, europe)\n",
    "\n",
    "# Investigate the result\n",
    "print(\"We located {} universities.\".format(len(universities)))\n",
    "print(\"Only {} of the universities were located in Europe (in {} different countries).\".format(\n",
    "    len(european_universities), len(european_universities.name.unique())))\n",
    "\n",
    "european_universities.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "4) Which counties look promising?\n",
    "Collapsing all of the information into a single GeoDataFrame also makes it much easier to select counties that meet specific criteria.\n",
    "\n",
    "Use the next code cell to create a GeoDataFrame sel_counties that contains a subset of the rows (and all of the columns) from the CA_stats GeoDataFrame. In particular, you should select counties where:\n",
    "\n",
    "there are at least 100,000 households making $150,000 per year,\n",
    "the median age is less than 38.5, and\n",
    "the density of inhabitants is at least 285 (per square kilometer).\n",
    "Additionally, selected counties should satisfy at least one of the following criteria:\n",
    "\n",
    "there are at least 500,000 households making $150,000 per year,\n",
    "the median age is less than 35.5, or\n",
    "the density of inhabitants is at least 1400 (per square kilometer).\n",
    "\n",
    "sel_counties = CA_stats[((CA_stats.high_earners > 100000) &\n",
    "                         (CA_stats.median_age < 38.5) &\n",
    "                         (CA_stats.density > 285) &\n",
    "                         ((CA_stats.median_age < 35.5) |\n",
    "                         (CA_stats.density > 1400) |\n",
    "                         (CA_stats.high_earners > 500000)))]\n",
    "\n",
    "#locaciones de starbusks\n",
    "starbucks_gdf = gpd.GeoDataFrame(starbucks, geometry=gpd.points_from_xy(starbucks.Longitude, starbucks.Latitude))\n",
    "starbucks_gdf.crs = {'init': 'epsg:4326'}\n",
    "\n",
    "# las uno con mi sel_counties y cuento la cantidad que satifagan esa condicion \n",
    "locations_of_interest = gpd.sjoin(starbucks_gdf,sel_counties)\n",
    "num_stores = len(locations_of_interest) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asegurarse uqe usen el mismo sistema de cooordenadas\n",
    "print(stations.crs)\n",
    "print(releases.crs)\n",
    "\n",
    "\n",
    "# Select one release incident in particular\n",
    "recent_release = releases.iloc[360]\n",
    "\n",
    "# Measure distance from release to each station\n",
    "distances = stations.geometry.distance(recent_release.geometry)\n",
    "distances\n",
    "\n",
    "print('Mean distance to monitoring stations: {} feet'.format(distances.mean()))\n",
    "print('Closest monitoring station ({} feet):'.format(distances.min()))\n",
    "print(stations.iloc[distances.idxmin()][[\"ADDRESS\", \"LATITUDE\", \"LONGITUDE\"]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Creating a buffer\n",
    "\n",
    "two_mile_buffer = stations.geometry.buffer(2*5280)\n",
    "two_mile_buffer.head()\n",
    "\n",
    "\n",
    "# Create map with release incidents and monitoring stations\n",
    "m = folium.Map(location=[39.9526,-75.1652], zoom_start=11)\n",
    "HeatMap(data=releases[['LATITUDE', 'LONGITUDE']], radius=15).add_to(m)\n",
    "for idx, row in stations.iterrows():\n",
    "    Marker([row['LATITUDE'], row['LONGITUDE']]).add_to(m)\n",
    "    \n",
    "# Plot each polygon on the map\n",
    "GeoJson(two_mile_buffer.to_crs(epsg=4326)).add_to(m)\n",
    "\n",
    "# Show the map\n",
    "m\n",
    "embed_map(m_1, \"q_1.html\")\n",
    "\n",
    "# Turn group of polygons into single multipolygon\n",
    "my_union = two_mile_buffer.geometry.unary_union\n",
    "print('Type:', type(my_union))\n",
    "\n",
    "# Show the MultiPolygon object\n",
    "my_union\n",
    "\n",
    "#Create a DataFrame outside_range containing all rows from collisions with crashes that occurred more than 10 kilometers from the closest hospital.5\n",
    "\n",
    "coverage = gpd.GeoDataFrame(geometry=hospitals.geometry).buffer(10000)\n",
    "my_union = coverage.geometry.unary_union\n",
    "outside_range = collisions.loc[~collisions[\"geometry\"].apply(lambda x: my_union.contains(x))]\n",
    "\n",
    "\n",
    "\n",
    "#FUNCION QUE DEVULEVE EL HOSPITAL MAS CERACANO\n",
    "def best_hospital(collision_location):\n",
    "    idx_min = hospitals.geometry.distance(collision_location).idxmin()\n",
    "    my_hospital = hospitals.iloc[idx_min]\n",
    "    name = my_hospital[\"name\"]\n",
    "    latitude = my_hospital[\"latitude\"]\n",
    "    longitude = my_hospital[\"longitude\"]\n",
    "    return pd.Series({'name': name, 'lat': latitude, 'long': longitude})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime # manipulating date formats\n",
    "# TIME SERIES\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf,arma_order_select_ic\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as scs\n",
    "\n",
    "\n",
    "#formatting the date column correctly\n",
    "sales.date=sales.date.apply(lambda x:datetime.datetime.strptime(x, '%d.%m.%Y'))\n",
    "\n",
    "\n",
    "# Aggregate to monthly level the required metrics\n",
    "\n",
    "monthly_sales=sales.groupby([\"date_block_num\",\"shop_id\",\"item_id\"])[\n",
    "    \"date\",\"item_price\",\"item_cnt_day\"].agg({\"date\":[\"min\",'max'],\"item_price\":\"mean\",\"item_cnt_day\":\"sum\"})\n",
    "\n",
    "## Lets break down the line of code here:\n",
    "# aggregate by date-block(month),shop_id and item_id\n",
    "# select the columns date,item_price and item_cnt(sales)\n",
    "# Provide a dictionary which says what aggregation to perform on which column\n",
    "# min and max on the date\n",
    "# average of the item_price\n",
    "# sum of the sales\n",
    "\n",
    "\n",
    "# number of items per cat \n",
    "x=item.groupby(['item_category_id']).count()\n",
    "x=x.sort_values(by='item_id',ascending=False)\n",
    "x=x.iloc[0:10].reset_index()\n",
    "x\n",
    "# #plot\n",
    "plt.figure(figsize=(8,4))\n",
    "ax= sns.barplot(x.item_category_id, x.item_id, alpha=0.8)\n",
    "plt.title(\"Items per Category\")\n",
    "plt.ylabel('# of items', fontsize=12)\n",
    "plt.xlabel('Category', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafico de la variable principal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "sns.distplot(train['SalePrice'] , fit=norm);\n",
    "\n",
    "# Get the fitted parameters used by the function\n",
    "(mu, sigma) = norm.fit(train['SalePrice'])\n",
    "print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n",
    "\n",
    "#Now plot the distribution\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n",
    "\n",
    "#Get also the QQ-plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(train['SalePrice'], plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grafico de dos variables y una pintada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot showing the relationship between 'pricepercent', 'winpercent', and 'chocolate'\n",
    " # Your code here\n",
    "sns.scatterplot(x='sugarpercent', y='winpercent',hue=\"chocolate\",data =candy_data)\n",
    "\n",
    "# sumarel linea de regresion\n",
    "sns.lmplot(x=\"pricepercent\", y=\"winpercent\", hue=\"chocolate\", data=candy_data)\n",
    "\n",
    "# scatterplot categorico\n",
    "sns.swarmplot(x=candy_data['chocolate'], y=candy_data['winpercent'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDE plot \n",
    "sns.kdeplot(data=iris_data['Petal Length (cm)'], shade=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D KDE plot\n",
    "sns.jointplot(x=iris_data['Petal Length (cm)'], y=iris_data['Sepal Width (cm)'], kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDE plots for benign and malignant tumors\n",
    "sns.kdeplot(data=cancer_b_data['Radius (worst)'], shade=True, label=\"Benign\")\n",
    "sns.kdeplot(data=cancer_m_data['Radius (worst)'], shade=True, label=\"Malignant\")\n",
    "# Check your answer\n",
    "step_4.a.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get categorical_cols and numerical_cols of the train dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = [cname for cname in trainingData2.columns if \n",
    "                trainingData2[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "categorical_cols = [cname for cname in trainingData2.columns if \n",
    "                   trainingData2[cname].dtype == \"object\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm going to check which columns are more useful to predict the Sale Price. For that I'm doing a heatmap. A heatmap shows the positive or negative correlation between the variable target that we want to predict and the variables that we are using to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop vthe column that you want to predict\n",
    "features=trainingData2.drop(columns=\"SalePrice\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =  features  #variables that will be useful to predict the target\n",
    "y = trainingData2[[\"SalePrice\"]] #the target variable that we want to predict\n",
    "cor = trainingData2.corr()\n",
    "plt.figure(figsize=(30,30))#change the size of the heatmap if you like\n",
    "\n",
    "\n",
    "\n",
    "g=sns.heatmap(cor,annot=True,cmap=\"Set1\") #plot the heatmap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#heat map mejorado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def heatMap(df):\n",
    "    #Create Correlation df\n",
    "    corr = df.corr()\n",
    "    #Plot figsize\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    #Generate Color Map\n",
    "    colormap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "    #Generate Heat Map, allow annotations and place floats in map\n",
    "    sns.heatmap(corr, cmap=colormap, annot=True, fmt=\".2f\")\n",
    "    #Apply xticks\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns);\n",
    "    #Apply yticks\n",
    "    plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "    #show plot\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\",\"Age\",\"Fare\",\"Survived\"]\n",
    "corr_data = pd.get_dummies(train_data[features])\n",
    "\n",
    "heatMap(corr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pintar correlaciones mayores a 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_target = abs(cor[\"SalePrice\"])\n",
    "relevant_features = cor_target[cor_target>0.5] #print the most relevant features: those with an absolute value of correlation with SalePrice superior to 0.5\n",
    "relevant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparar variables categoricas con la objetivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'YearBuilt'\n",
    "data = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\n",
    "f, ax = plt.subplots(figsize=(16, 8))\n",
    "fig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\n",
    "fig.axis(ymin=0, ymax=800000);\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRafio de las variables principales elegidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatterplot\n",
    "sns.set()\n",
    "cols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\n",
    "sns.pairplot(df_train[cols], size = 2.5)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skewness and kurtosis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skewness: %f\" % df_train['SalePrice'].skew())\n",
    "print(\"Kurtosis: %f\" % df_train['SalePrice'].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hustogramas de las variables categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot(variable):\n",
    "    \"\"\"\n",
    "        input: variable ex: \"Sex\"\n",
    "        output: bar plot & value count\n",
    "    \"\"\"\n",
    "    # get feature\n",
    "    var = train_df[variable]\n",
    "    # count number of categorical variable(value/sample)\n",
    "    varValue = var.value_counts()\n",
    "    \n",
    "    #visualize\n",
    "    plt.figure(figsize = (9,3))\n",
    "    plt.bar(varValue.index, varValue) # x axis: number of category(m/f), y axis: count of category\n",
    "    plt.xticks(varValue.index, varValue.index.values)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(variable)\n",
    "    plt.show()\n",
    "    print(\"{}: \\n {}\".format(variable,varValue))\n",
    "    \n",
    "    \n",
    "for i in (categorical_cols):\n",
    "    print(bar_plot(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def detect_outliers(df, features):\n",
    "    outlier_indices = []\n",
    "    \n",
    "    for c in features:\n",
    "        # 1st quartile\n",
    "        Q1 = np.percentile(df[c],25)\n",
    "        # 3rd quartile\n",
    "        Q3 = np.percentile(df[c],75)\n",
    "        # IQR\n",
    "        IQR = Q3 - Q1\n",
    "        # Outlier step\n",
    "        outlier_step = IQR * 1.5\n",
    "        # detect outlier and their indices\n",
    "        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 - outlier_step)].index\n",
    "        # store indices\n",
    "        outlier_indices.extend(outlier_list_col)\n",
    "    \n",
    "    outlier_indices = collections.Counter(outlier_indices)\n",
    "    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2) # If there are more than one outlier, drop it\n",
    "    \n",
    "    return multiple_outliers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# drop outliers\n",
    "#train_df = train_df.drop(detect_outliers(train_df,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"]),axis = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### separar valores en una colummna (ejemplo $10000 por mes)\n",
    "salary = data[\"salary\"].apply(lambda x: x.split('p')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the NaN values of each of the categorical columns with the mode of each one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in categorical_cols:\n",
    "    trainingData2[column].fillna(trainingData2[column].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the NaN values of each of the numerical columns with the median of each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in numerical_cols:\n",
    "    trainingData2[column].fillna(trainingData2[column].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### correlacion de variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data[[\"Columna1\n",
    "                \",\"Columna2\"]]\n",
    "\n",
    "sns.scatterplot(x=temp[\"Columna1\"],y =temp[\"Columna2\"])\n",
    "plt.title(\"Correlacion entre el Columna1 y Columna2  \");\n",
    "temp.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  generador de graficos de correlacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=data.drop(columns=\"Price\")\n",
    "features = features.columns.values.tolist()\n",
    "\n",
    "for columns  in features:\n",
    "    temp = data[[\"Price\",columns]]\n",
    "\n",
    "    sns.scatterplot(x=temp[\"Price\"],y =temp[columns]);\n",
    "    plt.title(\"Correlacion entre el Price y {}  \".format(columns));\n",
    "    temp.corr()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pasar valores por hora a anuales\n",
    "df['hourly']= df[\"Salary estimate\"].apply(lambda x: 1 if \"per hour\" in x.lower() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlacion con variables categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#box plot overallqual/saleprice\n",
    "var = 'OverallQual'\n",
    "data = pd.concat([df_train['SalePrice'], df_train[var]], axis=1)\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "fig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\n",
    "fig.axis(ymin=0, ymax=800000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correalacion 2 map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = df_train.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remplazar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['Columna'] == 2207,'Columna/'] = 2007\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = ks['category'] + \"_\" + ks['country']\n",
    "print(interactions.head(5))\n",
    "\n",
    "\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "data_interaction = baseline_data.assign(category_country=label_enc.fit_transform(interactions))\n",
    "data_interaction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNir gente con mismo ip en una cierta cantiad de horas\n",
    "  def count_past_events(series, time_window='6H'):\n",
    "        series = pd.Series(series.index, index=series)\n",
    "        # Subtract 1 so the current event isn't counted\n",
    "        past_events = series.rolling(time_window).count() - 1\n",
    "        return past_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Llenar los valores vacios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Columna\"] = data['columna'].fillna(full_df[\"YearBuilt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Condcioonar busqueda y contar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a1373a1d6438>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Coluumna1 == 1959'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Carpincho'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.query('Coluumna1 == 1959')['Carpincho'].value_counts()\n",
    "5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### dropear columnas con mas del 65% de los valores como  NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filter = data.loc[:, data.isnull().mean() <= .65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### lista de valores vacios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing data\n",
    "total = df_train.isnull().sum().sort_values(ascending=False)\n",
    "percent = (df_train.isnull().sum()/df_train.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Revisar valores vacios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-aab60b09e723>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfull_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'full_df' is not defined"
     ]
    }
   ],
   "source": [
    "full_df.isna().sum().sort_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generiacion de sub columna"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "full_df_ref_man = full_df[[\n",
    "                           'Street',\n",
    "                           'Exterior1st',\n",
    "                           'KitchenQual',\n",
    "                           'Heating',\n",
    "    \n",
    "                           'MSZoning',\n",
    "                           'YearBuilt',\n",
    "                           'Neighborhood',\n",
    "                           'Condition1',\n",
    "                           'BldgType',\n",
    "                           'HouseStyle',\n",
    "                           'OverallQual',\n",
    "                           'OverallCond',\n",
    "                           'ExterQual',\n",
    "                           'ExterCond', \n",
    "                           'BsmtQual',\n",
    "                           'BsmtCond',\n",
    "                           'CentralAir',\n",
    "                           'HeatingQC',\n",
    "                           'Electrical',\n",
    "                           '1stFlrSF',\n",
    "                           '2ndFlrSF',\n",
    "                           'GrLivArea',\n",
    "                           'FullBath',\n",
    "                           'BedroomAbvGr',\n",
    "                           'KitchenAbvGr',\n",
    "                           'Functional',\n",
    "                           'GarageType',\n",
    "                           'GarageQual',\n",
    "                           'OpenPorchSF',\n",
    "                           'PoolArea',\n",
    "                           'SaleType',\n",
    "                           'SaleCondition',\n",
    "                           'SalePrice'\n",
    "                          ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Generacion de variable dummy"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "full_df_upd_0 = pd.get_dummies(full_df_ref_man, drop_first=True)\n",
    "full_df_enc_2 = pd.get_dummies(full_df_ver2, drop_first=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "enc = OrdinalEncoder()\n",
    "full_df_ver2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert categorical variable into dummy\n",
    "df_train = pd.get_dummies(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Funcion para evaluar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(model, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    print('MAE train = ', mean_absolute_error(y_train, y_train_pred))\n",
    "    print('MAE test = ', mean_absolute_error(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduccion de dimensionalidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "feature_cols = clicks.columns.drop(['click_time', 'attributed_time', 'is_attributed'])\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "\n",
    "# Do feature extraction on the training data only!\n",
    "selector = SelectKBest(f_classif, k=40)\n",
    "X_new = selector.fit_transform(train[feature_cols], train['is_attributed'])\n",
    "\n",
    "# Get back the features we've kept, zero out all other features\n",
    "selected_features = pd.DataFrame(selector.inverse_transform(X_new), \n",
    "                                    index=train.index, \n",
    "                                    columns=feature_cols)\n",
    "\n",
    "# Dropped columns have values of all 0s, so var is 0, drop them\n",
    "dropped_columns = selected_features.columns[selected_features.var() == 0]\n",
    "\n",
    "# Check your answer\n",
    "q_2.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features_l1(X, y):\n",
    "    logistic = LogisticRegression(C=0.1, penalty=\"l1\", random_state=7).fit(X, y)\n",
    "    model = SelectFromModel(logistic, prefit=True)\n",
    "\n",
    "    X_new = model.transform(X)\n",
    "\n",
    "        # Get back the kept features as a DataFrame with dropped columns as all 0s\n",
    "    selected_features = pd.DataFrame(model.inverse_transform(X_new), \n",
    "                                        index=X.index,\n",
    "                                        columns=X.columns)\n",
    "\n",
    "        # Dropped columns have values of all 0s, keep other columns \n",
    "    cols_to_keep = selected_features.columns[selected_features.var() != 0]\n",
    "\n",
    "    return cols_to_keep\n",
    "# Check your answer\n",
    "q_4.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prueba de cardinalidad (cantidad de valore posibles en una variable categorica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns that will be one-hot encoded\n",
    "low_cardinality_cols = [col for col in object_cols if X_train[col].nunique() < 10]\n",
    "\n",
    "# Columns that will be dropped from the dataset\n",
    "high_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))\n",
    "\n",
    "print('Categorical columns that will be one-hot encoded:', low_cardinality_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', high_cardinality_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Make copy to avoid changing original data \n",
    "label_X_train = X_train.copy()\n",
    "label_X_valid = X_valid.copy()\n",
    "\n",
    "# Apply label encoder to each column with categorical data\n",
    "label_encoder = LabelEncoder()\n",
    "for col in object_cols:\n",
    "    label_X_train[col] = label_encoder.fit_transform(X_train[col])\n",
    "    label_X_valid[col] = label_encoder.transform(X_valid[col])\n",
    "\n",
    "print(\"MAE from Approach 2 (Label Encoding):\") \n",
    "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(data[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(data_t[low_cardinality_cols]))\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = data.index\n",
    "OH_cols_valid.index = data_t.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = data.drop(categorical_cols, axis=1)\n",
    "num_X_valid = data_t.drop(categorical_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "\n",
    "print(\"MAE from Approach 3 (One-Hot Encoding):\") \n",
    "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the encoder\n",
    "count_enc = ce.CountEncoder()\n",
    "\n",
    "# Transform the features, rename the columns with the _count suffix, and join to dataframe\n",
    "count_encoded = count_enc.fit_transform(ks[cat_features])\n",
    "data = data.join(count_encoded.add_suffix(\"_count\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the encoder\n",
    "target_enc = ce.TargetEncoder(cols=cat_features)\n",
    "target_enc.fit(train[cat_features], train['outcome'])\n",
    "\n",
    "# Transform the features, rename the columns with _target suffix, and join to dataframe\n",
    "train_TE = train.join(target_enc.transform(train[cat_features]).add_suffix('_target'))\n",
    "valid_TE = valid.join(target_enc.transform(valid[cat_features]).add_suffix('_target'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funciona como el target pero con la variable de la columna anterior\n",
    "\n",
    "target_enc = ce.CatBoostEncoder(cols=cat_features)\n",
    "target_enc.fit(train[cat_features], train['outcome'])\n",
    "\n",
    "# Transform the features, rename columns with _cb suffix, and join to dataframe\n",
    "train_CBE = train.join(target_enc.transform(train[cat_features]).add_suffix('_cb'))\n",
    "valid_CBE = valid.join(target_enc.transform(valid[cat_features]).add_suffix('_cb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis (analziar la calidad de un titulo por ejemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to remove stop words to decrease our runtime\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "def stop_words(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now let's go through our name column one last time. Since our sentiment analysis will only be applied to english, we should check to see if all the titles are in english. We will be using langdetect for this.\n",
    "\n",
    "from langdetect import detect\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "\n",
    "description = df['name'].astype(str)\n",
    "\n",
    "errors = []\n",
    "not_english = []\n",
    "english = 0\n",
    "other = 0\n",
    "for title in description:\n",
    "    try:\n",
    "        #print(title)\n",
    "        if detect(title) == 'en':\n",
    "            english += 1\n",
    "        else:\n",
    "            not_english += [title]\n",
    "            other += 1\n",
    "    except LangDetectException:\n",
    "        other += 1\n",
    "        errors += [title]\n",
    "english, other\n",
    "\n",
    "def grammar(string):\n",
    "    # add whatever else you think you might have to account for\n",
    "    result = str(string)\n",
    "    result = result.replace('/', ' ')\n",
    "    result = result.replace('*', ' ')\n",
    "    result = result.replace('&', ' ')\n",
    "    result = result.replace('>', ' ')\n",
    "    result = result.replace('<', ' ')\n",
    "    result = result.replace('-', ' ')\n",
    "    result = result.replace('...', ' ')\n",
    "    result = result.replace('@', ' ')\n",
    "    result = result.replace('#', ' ')\n",
    "    result = result.replace('-', ' ')\n",
    "    result = result.replace('$', ' ')\n",
    "    result = result.replace('%', ' ')\n",
    "    result = result.replace('+', ' ')\n",
    "    result = result.replace('=', ' ')\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "import langid\n",
    "desc = description.apply(grammar)\n",
    "langid.set_languages(['en', 'es', 'zh'])\n",
    "not_en = []\n",
    "not_en_index = []\n",
    "i = 0\n",
    "for title in desc:\n",
    "    if langid.classify(title)[0] != 'en':\n",
    "        not_en += [title]\n",
    "        not_en_index += [desc.index[i]]\n",
    "    i += 1\n",
    "    \n",
    "len(not_en)\n",
    "\n",
    "for i in desc.index:\n",
    "    if desc[i] in not_en:\n",
    "        desc[i] = ''\n",
    "\n",
    "        \n",
    "        To use VADER, we have to put our names into a single string\n",
    "\n",
    "# creating a function to convert a list of strings to single string\n",
    "def to_single_string(list_of_strings):\n",
    "    result = ''\n",
    "    for string in list_of_strings:\n",
    "        result += ' ' +string\n",
    "    return result\n",
    "\n",
    "# applying above function\n",
    "description = description.apply(to_single_string)\n",
    "description\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_score(string):\n",
    "        result = sentiment_analyzer.polarity_scores(string)\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    \n",
    "    sentiment = description.apply(sentiment_score)\n",
    "sentiment\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# method 1\n",
    "def compound_score(sent):\n",
    "    return sent.get('compound')\n",
    "\n",
    "sentiment_M1 = sentiment.apply(compound_score)\n",
    "sentiment_M1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# method 2\n",
    "def polarity(sent):\n",
    "    compound = sent.get('compound')\n",
    "    if(compound >= 0.05):\n",
    "        return 1\n",
    "    elif(compound <= -0.05):\n",
    "        return -1\n",
    "    return 0\n",
    "\n",
    "sentiment_M2 = sentiment.apply(polarity)\n",
    "sentiment_M2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test-train-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = OH_X_train\n",
    "y = OH_X_train[\"SalePrice\"]\n",
    "X_valid = OH_X_valid\n",
    "X.drop([\"SalePrice\"], axis =1 , inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRINCIPAL COMPONENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn import datasets\n",
    "class PCA:\n",
    "  def __init__(self, n_components):\n",
    "    self.n_components = n_components\n",
    "    self.components = None\n",
    "    self.mean = None\n",
    "\n",
    "  def fit(self, X):\n",
    "    self.mean = np.mean(X, axis=0)\n",
    "    X = X - self.mean\n",
    "    cov = np.cov(X.T)\n",
    "\n",
    "    evalue, evector = np.linalg.eig(cov)\n",
    "\n",
    "    eigenvectors = evector.T\n",
    "    idxs = np.argsort(evalue)[::-1]\n",
    "    \n",
    "    evalue = evalue[idxs]\n",
    "    evector = evector[idxs]\n",
    "    self.components = evector[0:self.n_components]\n",
    "\n",
    "  def transform(self, X):\n",
    "    #project data\n",
    "    X = X - self.mean\n",
    "    return(np.dot(X, self.components.T))\n",
    "\n",
    "data = datasets.load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "pca = PCA(2)\n",
    "pca.fit(X)\n",
    "X_projected = pca.transform(X)\n",
    "\n",
    "\n",
    "\n",
    "x1 = X_projected[:,0]\n",
    "x2 = X_projected[:,1]\n",
    "\n",
    "plt.scatter(x1,x2,c=y,edgecolor='none',alpha=0.8,cmap=plt.cm.get_cmap('viridis',3))\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select k best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X=dataframe.drop(['comprar'], axis=1)\n",
    "y=dataframe['comprar']\n",
    " \n",
    "best=SelectKBest(k=5)\n",
    "X_new = best.fit_transform(X, y)\n",
    "X_new.shape\n",
    "selected = best.get_support(indices=True)\n",
    "print(X.columns[selected])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estandarizar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saleprice_scaled = StandardScaler().fit_transform(df_train['SalePrice'][:,np.newaxis]);\n",
    "low_range = saleprice_scaled[saleprice_scaled[:,0].argsort()][:10]\n",
    "high_range= saleprice_scaled[saleprice_scaled[:,0].argsort()][-10:]\n",
    "print('outer range (low) of the distribution:')\n",
    "print(low_range)\n",
    "print('\\nouter range (high) of the distribution:')\n",
    "print(high_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eg 2\n",
    "temp_train_m1 = X_train_m1[:, X_train_m1.shape[1]-4:].toarray()\n",
    "temp_train_m2 = X_train_m2[:, X_train_m2.shape[1]-4: X_test_m2.shape[1]-1].toarray()\n",
    "\n",
    "temp_test_m1 = X_test_m1[:, X_test_m1.shape[1]-4:].toarray()\n",
    "temp_test_m2 = X_test_m2[:, X_test_m2.shape[1]-4: X_test_m2.shape[1]-1].toarray()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_m1 = StandardScaler().fit(temp_train_m1)\n",
    "scaler_m2 = StandardScaler().fit(temp_train_m2)\n",
    "\n",
    "temp_train_m1 = scaler_m1.transform(temp_train_m1)\n",
    "temp_train_m2 = scaler_m2.transform(temp_train_m2)\n",
    "\n",
    "temp_test_m1 = scaler_m1.transform(temp_test_m1)\n",
    "temp_test_m2 = scaler_m2.transform(temp_test_m2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train_m1[:,X_train_m1.shape[1]-4:] = sparse.csr_matrix(temp_train_m1)\n",
    "X_train_m2[:,X_train_m2.shape[1]-4: X_test_m2.shape[1]-1] = sparse.csr_matrix(temp_train_m2)\n",
    "\n",
    "X_test_m1[:,X_test_m1.shape[1]-4: ] = sparse.csr_matrix(temp_test_m1)\n",
    "X_test_m2[:,X_test_m2.shape[1]-4: X_test_m2.shape[1]-1] = sparse.csr_matrix(temp_test_m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduccion de dimensionalidad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Univariate Feature Selection\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "feature_cols = baseline_data.columns.drop('outcome')\n",
    "\n",
    "# Keep 5 features\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "\n",
    "X_new = selector.fit_transform(baseline_data[feature_cols], baseline_data['outcome'])\n",
    "X_new\n",
    "# usamos solo los datos de entrenamoiento para eviar lakeage \n",
    "\n",
    "feature_cols = baseline_data.columns.drop('outcome')\n",
    "train, valid, _ = get_data_splits(baseline_data)\n",
    "\n",
    "# Keep 5 features\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "\n",
    "X_new = selector.fit_transform(train[feature_cols], train['outcome'])\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### l1 or lasso regularizarion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "train, valid, _ = get_data_splits(baseline_data)\n",
    "\n",
    "X, y = train[train.columns.drop(\"outcome\")], train['outcome']\n",
    "\n",
    "# Set the regularization parameter C=1\n",
    "logistic = LogisticRegression(C=1, penalty=\"l1\", solver='liblinear', random_state=7).fit(X, y)\n",
    "model = SelectFromModel(logistic, prefit=True)\n",
    "\n",
    "X_new = model.transform(X)\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get back the kept features as a DataFrame with dropped columns as all 0s\n",
    "selected_features = pd.DataFrame(model.inverse_transform(X_new), \n",
    "                                 index=X.index,\n",
    "                                 columns=X.columns)\n",
    "\n",
    "# Dropped columns have values of all 0s, keep other columns \n",
    "selected_columns = selected_features.columns[selected_features.var() != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysisi multivariable\n",
    " * Normality \n",
    " * Homoscedasticity \n",
    " * Linearity\n",
    " * Absence of correlated errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicacion de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "modelXGB = xgb.XGBRegressor(max_depth=2)\n",
    "\n",
    "modelXGB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "predictionsXGB = modelXGB.predict(X_valid)\n",
    "\n",
    "# Calculate MAE\n",
    "maeXGB = mean_absolute_error(predictionsXGB, y_valid)\n",
    "print(\"Mean Absolute Error:\" , maeXGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFModel=RandomForestRegressor(random_state=0)\n",
    "RFModel.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsRF= RFModel.predict(X_valid)\n",
    "\n",
    "#mean absolute error\n",
    "maeRF = mean_absolute_error(predictionsRF, y_valid)\n",
    "print(\"Mean Absolute Error:\" , maeRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#use the best model to predict test\n",
    "predictionsTest=modelXGB.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "feature_cols = train.columns.drop('outcome')\n",
    "\n",
    "dtrain = lgb.Dataset(train[feature_cols], label=train['outcome'])\n",
    "dvalid = lgb.Dataset(valid[feature_cols], label=valid['outcome'])\n",
    "\n",
    "param = {'num_leaves': 64, 'objective': 'binary'}\n",
    "param['metric'] = 'auc'\n",
    "num_round = 1000\n",
    "bst = lgb.train(param, dtrain, num_round, valid_sets=[dvalid], early_stopping_rounds=10, verbose_eval=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using TheilSen Regresor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import  TheilSenRegressor\n",
    "model = TheilSenRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANSAC Regressor¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import  RANSACRegressor\n",
    "model = RANSACRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huber Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import  HuberRegressor\n",
    "model = HuberRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-6fcc0b3607b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=5)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter = 500000)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "\n",
    "\n",
    "\n",
    "##Report\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-eb1b57df5ec8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Process Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-4e3b85807093>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgaussian_process\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGaussianProcessClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGaussianProcessClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=5)\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "model = GaussianProcessClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "\n",
    "\n",
    "##report \n",
    "\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "data_svm = pd.read_csv(\"../input/svm-classification/UniversalBank.csv\")\n",
    "data_svm.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = data_svm.iloc[:,1:13].values\n",
    "y = data_svm.iloc[:, -1].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "accuracies.mean()\n",
    "#report\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nu Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import NuSVC\n",
    "nu_svm = pd.read_csv(\"../input/svm-classification/UniversalBank.csv\")\n",
    "nu_svm.head()\n",
    "\n",
    "\n",
    "\n",
    "X = nu_svm.iloc[:,1:13].values\n",
    "y = nu_svm.iloc[:, -1].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "classifier = NuSVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "accuracies.mean()\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "data = pd.read_csv('../input/classification-suv-dataset/Social_Network_Ads.csv')\n",
    "data_nb = data\n",
    "data_nb.head()\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gaussian NB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_nb.iloc[:, [2,3]].values\n",
    "y = data_nb.iloc[:, 4].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "classifier=GaussianNB()\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "acc=accuracy_score(y_test, y_pred)\n",
    "print(acc)\n",
    "\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_nb.iloc[:, [2,3]].values\n",
    "y = data_nb.iloc[:, 4].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "classifier=BernoulliNB()\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "acc=accuracy_score(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-221bda6bfc4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = pd.read_csv(\"../input/iris/Iris.csv\")\n",
    "knn.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = knn.iloc[:, [1,2,3,4]].values\n",
    "y = knn.iloc[:, 5].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "classifier=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "acc=accuracy_score(y_test, y_pred)\n",
    "print(acc)\n",
    "\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### As Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "train = pd.read_csv(\"../input/random-linear-regression/train.csv\") \n",
    "test = pd.read_csv(\"../input/random-linear-regression/test.csv\") \n",
    "train = train.dropna()\n",
    "test = test.dropna()\n",
    "X_train = np.array(train.iloc[:, :-1].values)\n",
    "y_train = np.array(train.iloc[:, 1].values)\n",
    "X_test = np.array(test.iloc[:, :-1].values)\n",
    "y_test = np.array(test.iloc[:, 1].values)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=2)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron (Single layer neural network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "p = pd.read_csv(\"../input/iris/Iris.csv\")\n",
    "p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = p.iloc[:, [1,2,3,4]].values\n",
    "y = p.iloc[:, 5].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "classifier=Perceptron()\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "acc=accuracy_score(y_test, y_pred)\n",
    "print(acc)\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = pd.read_csv(\"../input/mushroom-classification/mushrooms.csv\")\n",
    "rf.head()\n",
    "\n",
    "\n",
    "X = rf.drop('class', axis=1)\n",
    "y = rf['class']\n",
    "X = pd.get_dummies(X)\n",
    "y = pd.get_dummies(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = data\n",
    "dt.head()\n",
    "\n",
    "X = dt.iloc[:, [2,3]].values\n",
    "y = dt.iloc[:, 4].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "classifier=DecisionTreeClassifier(criterion=\"entropy\",random_state=0)\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "acc=accuracy_score(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "et = data\n",
    "et.head()\n",
    "\n",
    "\n",
    "\n",
    "X = et.iloc[:, [2,3]].values\n",
    "y = et.iloc[:, 4].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "classifier=ExtraTreesClassifier(criterion=\"entropy\",random_state=0)\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "acc=accuracy_score(y_test, y_pred)\n",
    "print(acc)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ac = data\n",
    "ac.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ac.iloc[:, [2,3]].values\n",
    "y = ac.iloc[:, 4].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "classifier=AdaBoostClassifier(random_state=0)\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "acc=accuracy_score(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passive Aggressive Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-5f4298783d3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPassiveAggressiveClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpac\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpac\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "pac = data\n",
    "pac.head()\n",
    "\n",
    "X = pac.iloc[:, [2,3]].values\n",
    "y = pac.iloc[:, 4].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "classifier=PassiveAggressiveClassifier(random_state=0)\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "acc=accuracy_score(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bc = data\n",
    "bc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bc.iloc[:, [2,3]].values\n",
    "y = bc.iloc[:, 4].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "classifier=BaggingClassifier(random_state=0)\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "acc=accuracy_score(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-3e056cd8e0d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = data\n",
    "gb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = gb.iloc[:, [2,3]].values\n",
    "y = gb.iloc[:, 4].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "gbk = GradientBoostingClassifier()\n",
    "gbk.fit(X_train, y_train)\n",
    "pred = gbk.predict(X_test)\n",
    "acc=accuracy_score(y_test, y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/train.csv\")\n",
    "test = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/test.csv\")\n",
    "data = pd.concat([train, test], sort=False)\n",
    "data = data.reset_index(drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_list = []\n",
    "for col in data.columns:\n",
    "    if type(data[col][0]) == type('str'): \n",
    "        _list.append(col)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "for li in _list:\n",
    "    le.fit(list(set(data[li])))\n",
    "    data[li] = le.transform(data[li])\n",
    "\n",
    "train, test = data[:len(train)], data[len(train):]\n",
    "\n",
    "X = train.drop(columns=['SalePrice', 'Id']) \n",
    "y = train['SalePrice']\n",
    "\n",
    "test = test.drop(columns=['SalePrice', 'Id'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "model_lgb.fit(X, y)\n",
    "r2_score(model_lgb.predict(X), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost <3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import xgboost as xgb\n",
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)\n",
    "model_xgb.fit(X_train, y_train)\n",
    "r2_score(model_xgb.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pasar parametros con un diccionario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrena el combinatorio con todos los parametros \n",
    "xgb = xgboost.SGBClassifier()\n",
    "parameters = {\"nthreads\": [1],\n",
    "             \"objetive\":[\"binary:logistic\"],\n",
    "             \"learning_rate\": [0.05,0.1],\n",
    "             \"n_estimators\":[100, 200]}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "fit_params = {\"early_stopping_rounds\":10,\n",
    "             \"eval_metric\": \"logloss\",\n",
    "             \"eval_set\":[(X_test, y_test)]}\n",
    "\n",
    "clf =GridSearchCV(xgb, parameters, fit_params = fit_params,\n",
    "                 cv=3 , scoring=\"accuracy\")\n",
    "clf.fit(X_train,Y_train)\n",
    "clf.best_estimator\n",
    "clf.best_score\n",
    "from sklearn.metrics import accuaracy_score\n",
    "best_xgb = clf.best_estimator\n",
    "\n",
    "best_xgb.predict(X_valid)\n",
    "\n",
    "y_preds =  best_xgb.predict(X_valid)\n",
    "\n",
    "comp = pd.DataFrame(\"real\":y_valid, \"pred\":y_preds)\n",
    "comp.head(20)\n",
    "\n",
    "\n",
    "acc = acciracy_score(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### description : Catboost is a type of gradient boosting algorithms which can automatically deal with categorical variables without showing the type conversion error, which helps you to focus on tuning your model better rather than sorting out trivial errors.Make sure you handle missing data well before you proceed with the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "#Data is used the same as LGB\n",
    "X = train.drop(columns=['SalePrice', 'Id']) \n",
    "y = train['SalePrice']\n",
    "X.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cb_model = CatBoostRegressor(iterations=500,\n",
    "                             learning_rate=0.05,\n",
    "                             depth=10,\n",
    "                             random_seed = 42,\n",
    "                             bagging_temperature = 0.2,\n",
    "                             od_type='Iter',\n",
    "                             metric_period = 50,\n",
    "                             od_wait=20)\n",
    "cb_model.fit(X, y)\n",
    "r2_score(cb_model.predict(X), y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-26a276f6c3b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSGDRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#Data is used the same as LGB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SalePrice'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SalePrice'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "#Data is used the same as LGB\n",
    "X = train.drop(columns=['SalePrice', 'Id']) \n",
    "y = train['SalePrice']\n",
    "X.head()\n",
    "\n",
    "\n",
    "SGD = SGDRegressor(max_iter = 100)\n",
    "SGD.fit(X, y)\n",
    "r2_score(SGD.predict(X), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-3fa44049b903>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRobustScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Data is used the same as LGB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SalePrice'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SalePrice'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "#Data is used the same as LGB\n",
    "X = train.drop(columns=['SalePrice', 'Id']) \n",
    "y = train['SalePrice']\n",
    "X.head()\n",
    "\n",
    "\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "lasso.fit(X, y)\n",
    "r2_score(lasso.predict(X), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Classifier CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-d52d8587ae5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRidgeClassifierCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#Data is used the same as LGB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SalePrice'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SalePrice'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "#Data is used the same as LGB\n",
    "X = train.drop(columns=['SalePrice', 'Id']) \n",
    "y = train['SalePrice']\n",
    "X.head()\n",
    "\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "#Data is used the same as LGB\n",
    "X = train.drop(columns=['SalePrice', 'Id']) \n",
    "y = train['SalePrice']\n",
    "X.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model  import BayesianRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "#Data is used the same as LGB\n",
    "X = train.drop(columns=['SalePrice', 'Id']) \n",
    "y = train['SalePrice']\n",
    "X.head()\n",
    "\n",
    "BR = BayesianRidge()\n",
    "BR.fit(X, y)\n",
    "r2_score(BR.predict(X), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = data\n",
    "lda.head()\n",
    "\n",
    "X = lda.iloc[:, [2,3]].values\n",
    "y = lda.iloc[:, 4].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "Model=LinearDiscriminantAnalysis()\n",
    "Model.fit(X_train,y_train)\n",
    "y_pred=Model.predict(X_test)\n",
    "print('accuracy is ',accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K- MEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "km = pd.read_csv(\"../input/k-mean/km.csv\")\n",
    "km.head()\n",
    "\n",
    "\n",
    "K_clusters = range(1,8)\n",
    "kmeans = [KMeans(n_clusters=i) for i in K_clusters]\n",
    "Y_axis = km[['latitude']]\n",
    "X_axis = km[['longitude']]\n",
    "score = [kmeans[i].fit(Y_axis).score(Y_axis) for i in range(len(kmeans))]\n",
    "plt.plot(K_clusters, score)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Score')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters = 3, init ='k-means++')\n",
    "kmeans.fit(km[km.columns[1:3]])\n",
    "km['cluster_label'] = kmeans.fit_predict(km[km.columns[1:3]])\n",
    "centers = kmeans.cluster_centers_\n",
    "labels = kmeans.predict(km[km.columns[1:3]])\n",
    "km.cluster_label.unique()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "km.plot.scatter(x = 'latitude', y = 'longitude', c=labels, s=50, cmap='viridis')\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=100, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "import tensorflow as tf\n",
    "train_data = pd.read_csv(\"../input/digit-recognizer/train.csv\")\n",
    "test_data = pd.read_csv(\"../input/digit-recognizer/test.csv\")\n",
    "train_data.head()\n",
    "\n",
    "\n",
    "X = np.array(train_data.drop(\"label\", axis=1)).astype('float32')\n",
    "y = np.array(train_data['label']).astype('float32')\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X[i].reshape(28, 28), cmap=plt.cm.binary)\n",
    "    plt.xlabel(y[i])\n",
    "plt.show()\n",
    "\n",
    "X = X / 255.0\n",
    "X = X.reshape(-1, 28, 28, 1)\n",
    "y = to_categorical(y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "X_test = np.array(test_data).astype('float32')\n",
    "X_test = X_test / 255.0\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))\n",
    "model.summary()\n",
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='model1.png')\n",
    "\n",
    "\n",
    "\n",
    "#increse to epochs to 30 for better accuracy\n",
    "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=85, validation_data=(X_val, y_val))\n",
    "\n",
    "\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.show()\n",
    "\n",
    "print(model.evaluate(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluacion del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.SGBClassifier()\n",
    "parameters = {\"nthreads\": [1],\n",
    "             \"objetive\":[\"binary:logistic\"],\n",
    "             \"learning_rate\": [0.05,0.1],\n",
    "             \"n_estimators\":[100, 200]}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "fit_params = {\"early_stopping_rounds\":10,\n",
    "             \"eval_metric\": \"logloss\",\n",
    "             \"eval_set\":[(X_test, y_test)]}\n",
    "\n",
    "clf =GridSearchCV(xgb, parameters, fit_params = fit_params,\n",
    "                 cv=3 , scoring=\"accuracy\")\n",
    "clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(model, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    print('MAE train = ', mean_absolute_error(y_train, y_train_pred))\n",
    "    print('MAE test = ', mean_absolute_error(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = []\n",
    "models += [['SVM', SVR(kernel = 'linear')]]\n",
    "models += [['Lasso', Lasso(alpha = 0.9, normalize = False, selection = 'cyclic')]]\n",
    "models += [['Ridge', Ridge(alpha = 0.9, normalize = False, solver = 'auto')]]\n",
    "models += [['Linear', LinearRegression(normalize = False)]]\n",
    "models += [['Random Forests', RandomForestClassifier(n_estimators = 100, max_features = X_test_m1.shape[1], random_state = 42, max_depth = 9)]]\n",
    "\n",
    "# for the k fold cross validation\n",
    "kfold = KFold(n_splits = 10, random_state = 1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "result_m1 =[]\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    cv_score = -1 * cross_val_score(model, X_train_m1, y_train_m1, cv = kfold, scoring = 'neg_mean_absolute_error')\n",
    "    result_m1 +=[cv_score]\n",
    "    names += [name]\n",
    "    print('%s: %f (%f)' % (name,cv_score.mean(), cv_score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medir datasets desbalanciados\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(random_forest_pred,y_test)\n",
    "\n",
    "\n",
    "pd.DataFrame(confusion_matrix(random_forest_pred,y_test))\n",
    "\n",
    "\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test,random_forest_pred),cmap='viridis',annot=True,fmt='.2f')\n",
    "plt.savefig('random.png')\n",
    "plt.show()\n",
    "\n",
    "recall_score(random_forest_pred,y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(random_forest_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "estimator = KerasRegressor(build_fn = neural_net, epochs = 1000, batch_size = 2000, verbose=0)\n",
    "results = -1 * cross_val_score(estimator, X_train_m1, y_train_m1, cv = kfold, scoring = 'neg_mean_absolute_error')\n",
    "print(\"Neural net: %f (%f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(my_model, random_state=1).fit(val_X, val_y)\n",
    "eli5.show_weights(perm, feature_names = val_X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importante analizar LEAKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
